# 负载均衡与流量分发

## 背景
随着互联网业务的快速发展，单台服务器已无法承载海量用户请求，负载均衡成为分布式系统架构中的核心组件。负载均衡通过将请求分发到多个服务器实例，实现系统的水平扩展、提高可用性和性能。在微服务架构中，负载均衡不仅存在于网关层，还广泛应用于服务间调用、数据库访问等场景。合理的负载均衡策略能够最大化资源利用率，提供更好的用户体验。

## 核心原理

### 1. 负载均衡基本概念

#### 负载均衡器类型
- **硬件负载均衡器**：F5、A10等专用设备，性能强但成本高
- **软件负载均衡器**：Nginx、HAProxy、LVS等，灵活性好，成本低
- **云负载均衡器**：AWS ELB、阿里云SLB等，托管服务，易于使用

#### 工作层次
- **L4负载均衡**：基于传输层（TCP/UDP），转发速度快，功能相对简单
- **L7负载均衡**：基于应用层（HTTP/HTTPS），功能丰富，可以基于内容路由

### 2. 负载均衡算法

#### 轮询算法（Round Robin）
```go
// 简单轮询实现
type RoundRobinBalancer struct {
    servers []Server
    current int64
    mu      sync.Mutex
}

type Server struct {
    ID      string
    Address string
    Weight  int
    Active  bool
}

func NewRoundRobinBalancer(servers []Server) *RoundRobinBalancer {
    return &RoundRobinBalancer{
        servers: servers,
        current: 0,
    }
}

func (rb *RoundRobinBalancer) NextServer() *Server {
    rb.mu.Lock()
    defer rb.mu.Unlock()
    
    if len(rb.servers) == 0 {
        return nil
    }
    
    // 找到下一个活跃的服务器
    for i := 0; i < len(rb.servers); i++ {
        index := (rb.current + int64(i)) % int64(len(rb.servers))
        server := &rb.servers[index]
        
        if server.Active {
            rb.current = index + 1
            return server
        }
    }
    
    return nil
}
```

#### 加权轮询算法（Weighted Round Robin）
```go
// 加权轮询实现
type WeightedRoundRobinBalancer struct {
    servers []WeightedServer
    mu      sync.Mutex
}

type WeightedServer struct {
    Server
    CurrentWeight int
    EffectiveWeight int
}

func NewWeightedRoundRobinBalancer(servers []Server) *WeightedRoundRobinBalancer {
    weightedServers := make([]WeightedServer, len(servers))
    for i, server := range servers {
        weightedServers[i] = WeightedServer{
            Server:          server,
            CurrentWeight:   0,
            EffectiveWeight: server.Weight,
        }
    }
    
    return &WeightedRoundRobinBalancer{
        servers: weightedServers,
    }
}

func (wrb *WeightedRoundRobinBalancer) NextServer() *Server {
    wrb.mu.Lock()
    defer wrb.mu.Unlock()
    
    if len(wrb.servers) == 0 {
        return nil
    }
    
    totalWeight := 0
    var selected *WeightedServer
    
    for i := range wrb.servers {
        server := &wrb.servers[i]
        if !server.Active {
            continue
        }
        
        // 增加当前权重
        server.CurrentWeight += server.EffectiveWeight
        totalWeight += server.EffectiveWeight
        
        // 选择当前权重最大的服务器
        if selected == nil || server.CurrentWeight > selected.CurrentWeight {
            selected = server
        }
    }
    
    if selected != nil {
        // 减少选中服务器的当前权重
        selected.CurrentWeight -= totalWeight
        return &selected.Server
    }
    
    return nil
}
```

#### 最少连接算法（Least Connections）
```go
// 最少连接实现
type LeastConnectionsBalancer struct {
    servers []ConnectionServer
    mu      sync.RWMutex
}

type ConnectionServer struct {
    Server
    ActiveConnections int64
}

func NewLeastConnectionsBalancer(servers []Server) *LeastConnectionsBalancer {
    connServers := make([]ConnectionServer, len(servers))
    for i, server := range servers {
        connServers[i] = ConnectionServer{
            Server:            server,
            ActiveConnections: 0,
        }
    }
    
    return &LeastConnectionsBalancer{
        servers: connServers,
    }
}

func (lcb *LeastConnectionsBalancer) NextServer() *Server {
    lcb.mu.RLock()
    defer lcb.mu.RUnlock()
    
    var selected *ConnectionServer
    minConnections := int64(math.MaxInt64)
    
    for i := range lcb.servers {
        server := &lcb.servers[i]
        if !server.Active {
            continue
        }
        
        connections := atomic.LoadInt64(&server.ActiveConnections)
        if connections < minConnections {
            minConnections = connections
            selected = server
        }
    }
    
    if selected != nil {
        atomic.AddInt64(&selected.ActiveConnections, 1)
        return &selected.Server
    }
    
    return nil
}

func (lcb *LeastConnectionsBalancer) ReleaseConnection(serverID string) {
    lcb.mu.RLock()
    defer lcb.mu.RUnlock()
    
    for i := range lcb.servers {
        if lcb.servers[i].ID == serverID {
            atomic.AddInt64(&lcb.servers[i].ActiveConnections, -1)
            break
        }
    }
}
```

#### 一致性哈希算法（Consistent Hashing）
```go
// 一致性哈希实现
type ConsistentHashBalancer struct {
    hashRing map[uint32]string // 哈希环
    sortedHashes []uint32      // 排序的哈希值
    servers map[string]Server  // 服务器映射
    replicas int               // 虚拟节点数量
    mu sync.RWMutex
}

func NewConsistentHashBalancer(replicas int) *ConsistentHashBalancer {
    return &ConsistentHashBalancer{
        hashRing:     make(map[uint32]string),
        servers:      make(map[string]Server),
        replicas:     replicas,
        sortedHashes: make([]uint32, 0),
    }
}

func (chb *ConsistentHashBalancer) AddServer(server Server) {
    chb.mu.Lock()
    defer chb.mu.Unlock()
    
    chb.servers[server.ID] = server
    
    // 为每个服务器创建多个虚拟节点
    for i := 0; i < chb.replicas; i++ {
        virtualKey := fmt.Sprintf("%s#%d", server.ID, i)
        hash := chb.hash(virtualKey)
        chb.hashRing[hash] = server.ID
        chb.sortedHashes = append(chb.sortedHashes, hash)
    }
    
    sort.Slice(chb.sortedHashes, func(i, j int) bool {
        return chb.sortedHashes[i] < chb.sortedHashes[j]
    })
}

func (chb *ConsistentHashBalancer) RemoveServer(serverID string) {
    chb.mu.Lock()
    defer chb.mu.Unlock()
    
    delete(chb.servers, serverID)
    
    // 移除虚拟节点
    newHashes := make([]uint32, 0)
    for _, hash := range chb.sortedHashes {
        if chb.hashRing[hash] != serverID {
            newHashes = append(newHashes, hash)
        } else {
            delete(chb.hashRing, hash)
        }
    }
    chb.sortedHashes = newHashes
}

func (chb *ConsistentHashBalancer) GetServer(key string) *Server {
    chb.mu.RLock()
    defer chb.mu.RUnlock()
    
    if len(chb.sortedHashes) == 0 {
        return nil
    }
    
    hash := chb.hash(key)
    
    // 找到第一个大于等于hash的节点
    idx := sort.Search(len(chb.sortedHashes), func(i int) bool {
        return chb.sortedHashes[i] >= hash
    })
    
    // 如果没找到，则使用第一个节点（环形结构）
    if idx == len(chb.sortedHashes) {
        idx = 0
    }
    
    serverID := chb.hashRing[chb.sortedHashes[idx]]
    if server, exists := chb.servers[serverID]; exists && server.Active {
        return &server
    }
    
    return nil
}

func (chb *ConsistentHashBalancer) hash(key string) uint32 {
    h := fnv.New32a()
    h.Write([]byte(key))
    return h.Sum32()
}
```

#### 加权最少连接算法（Weighted Least Connections）
```go
// 加权最少连接实现
type WeightedLeastConnectionsBalancer struct {
    servers []WeightedConnectionServer
    mu      sync.RWMutex
}

type WeightedConnectionServer struct {
    Server
    ActiveConnections int64
    Weight           int
}

func (wlcb *WeightedLeastConnectionsBalancer) NextServer() *Server {
    wlcb.mu.RLock()
    defer wlcb.mu.RUnlock()
    
    var selected *WeightedConnectionServer
    minRatio := float64(math.MaxFloat64)
    
    for i := range wlcb.servers {
        server := &wlcb.servers[i]
        if !server.Active || server.Weight == 0 {
            continue
        }
        
        connections := atomic.LoadInt64(&server.ActiveConnections)
        ratio := float64(connections) / float64(server.Weight)
        
        if ratio < minRatio {
            minRatio = ratio
            selected = server
        }
    }
    
    if selected != nil {
        atomic.AddInt64(&selected.ActiveConnections, 1)
        return &selected.Server
    }
    
    return nil
}
```

### 3. 健康检查机制

```go
// 健康检查器
type HealthChecker struct {
    servers    []Server
    checkURL   string
    interval   time.Duration
    timeout    time.Duration
    client     *http.Client
    mu         sync.RWMutex
    stopCh     chan struct{}
}

func NewHealthChecker(servers []Server, checkURL string, interval, timeout time.Duration) *HealthChecker {
    return &HealthChecker{
        servers:  servers,
        checkURL: checkURL,
        interval: interval,
        timeout:  timeout,
        client: &http.Client{
            Timeout: timeout,
        },
        stopCh: make(chan struct{}),
    }
}

func (hc *HealthChecker) Start() {
    ticker := time.NewTicker(hc.interval)
    defer ticker.Stop()
    
    for {
        select {
        case <-ticker.C:
            hc.checkAllServers()
        case <-hc.stopCh:
            return
        }
    }
}

func (hc *HealthChecker) Stop() {
    close(hc.stopCh)
}

func (hc *HealthChecker) checkAllServers() {
    var wg sync.WaitGroup
    
    for i := range hc.servers {
        wg.Add(1)
        go func(index int) {
            defer wg.Done()
            hc.checkServer(index)
        }(i)
    }
    
    wg.Wait()
}

func (hc *HealthChecker) checkServer(index int) {
    hc.mu.Lock()
    server := &hc.servers[index]
    hc.mu.Unlock()
    
    url := fmt.Sprintf("http://%s%s", server.Address, hc.checkURL)
    
    ctx, cancel := context.WithTimeout(context.Background(), hc.timeout)
    defer cancel()
    
    req, err := http.NewRequestWithContext(ctx, "GET", url, nil)
    if err != nil {
        hc.markServerDown(index)
        return
    }
    
    resp, err := hc.client.Do(req)
    if err != nil {
        hc.markServerDown(index)
        return
    }
    defer resp.Body.Close()
    
    if resp.StatusCode >= 200 && resp.StatusCode < 300 {
        hc.markServerUp(index)
    } else {
        hc.markServerDown(index)
    }
}

func (hc *HealthChecker) markServerUp(index int) {
    hc.mu.Lock()
    defer hc.mu.Unlock()
    
    if !hc.servers[index].Active {
        log.Printf("Server %s is back online", hc.servers[index].ID)
        hc.servers[index].Active = true
    }
}

func (hc *HealthChecker) markServerDown(index int) {
    hc.mu.Lock()
    defer hc.mu.Unlock()
    
    if hc.servers[index].Active {
        log.Printf("Server %s is down", hc.servers[index].ID)
        hc.servers[index].Active = false
    }
}

func (hc *HealthChecker) GetActiveServers() []Server {
    hc.mu.RLock()
    defer hc.mu.RUnlock()
    
    var activeServers []Server
    for _, server := range hc.servers {
        if server.Active {
            activeServers = append(activeServers, server)
        }
    }
    
    return activeServers
}
```

## 技术亮点

### 1. 动态权重调整
```go
// 基于响应时间的动态权重调整
type AdaptiveWeightBalancer struct {
    servers []AdaptiveServer
    mu      sync.RWMutex
}

type AdaptiveServer struct {
    Server
    ResponseTimes []time.Duration // 最近的响应时间
    MaxSamples    int            // 最大样本数
    BaseWeight    int            // 基础权重
    CurrentWeight int            // 当前权重
}

func (awb *AdaptiveWeightBalancer) RecordResponseTime(serverID string, responseTime time.Duration) {
    awb.mu.Lock()
    defer awb.mu.Unlock()
    
    for i := range awb.servers {
        if awb.servers[i].ID == serverID {
            server := &awb.servers[i]
            
            // 添加新的响应时间
            server.ResponseTimes = append(server.ResponseTimes, responseTime)
            
            // 保持样本数量在限制内
            if len(server.ResponseTimes) > server.MaxSamples {
                server.ResponseTimes = server.ResponseTimes[1:]
            }
            
            // 更新权重
            awb.updateWeight(server)
            break
        }
    }
}

func (awb *AdaptiveWeightBalancer) updateWeight(server *AdaptiveServer) {
    if len(server.ResponseTimes) == 0 {
        server.CurrentWeight = server.BaseWeight
        return
    }
    
    // 计算平均响应时间
    var total time.Duration
    for _, rt := range server.ResponseTimes {
        total += rt
    }
    avgResponseTime := total / time.Duration(len(server.ResponseTimes))
    
    // 基于响应时间调整权重（响应时间越短，权重越高）
    baseTime := 100 * time.Millisecond
    if avgResponseTime <= baseTime {
        server.CurrentWeight = server.BaseWeight * 2
    } else if avgResponseTime <= 2*baseTime {
        server.CurrentWeight = server.BaseWeight
    } else {
        server.CurrentWeight = server.BaseWeight / 2
    }
    
    // 确保权重不为0
    if server.CurrentWeight <= 0 {
        server.CurrentWeight = 1
    }
}
```

### 2. 会话保持（Session Affinity）
```go
// 基于IP哈希的会话保持
type SessionAffinityBalancer struct {
    balancer LoadBalancer
    sessions map[string]string // clientIP -> serverID
    mu       sync.RWMutex
    ttl      time.Duration
    cleanup  *time.Ticker
}

type SessionInfo struct {
    ServerID  string
    LastAccess time.Time
}

func NewSessionAffinityBalancer(balancer LoadBalancer, ttl time.Duration) *SessionAffinityBalancer {
    sab := &SessionAffinityBalancer{
        balancer: balancer,
        sessions: make(map[string]string),
        ttl:      ttl,
        cleanup:  time.NewTicker(ttl / 2),
    }
    
    go sab.cleanupExpiredSessions()
    return sab
}

func (sab *SessionAffinityBalancer) GetServer(clientIP string) *Server {
    sab.mu.RLock()
    serverID, exists := sab.sessions[clientIP]
    sab.mu.RUnlock()
    
    if exists {
        // 检查服务器是否仍然可用
        if server := sab.getServerByID(serverID); server != nil && server.Active {
            return server
        }
        
        // 服务器不可用，移除会话
        sab.mu.Lock()
        delete(sab.sessions, clientIP)
        sab.mu.Unlock()
    }
    
    // 获取新的服务器
    server := sab.balancer.NextServer()
    if server != nil {
        sab.mu.Lock()
        sab.sessions[clientIP] = server.ID
        sab.mu.Unlock()
    }
    
    return server
}

func (sab *SessionAffinityBalancer) cleanupExpiredSessions() {
    for {
        select {
        case <-sab.cleanup.C:
            sab.mu.Lock()
            now := time.Now()
            for clientIP, sessionInfo := range sab.sessions {
                if now.Sub(sessionInfo.LastAccess) > sab.ttl {
                    delete(sab.sessions, clientIP)
                }
            }
            sab.mu.Unlock()
        }
    }
}
```

### 3. 限流和熔断
```go
// 带限流的负载均衡器
type RateLimitedBalancer struct {
    balancer    LoadBalancer
    rateLimiter *RateLimiter
    circuitBreaker *CircuitBreaker
}

type RateLimiter struct {
    limit    int
    window   time.Duration
    requests map[string][]time.Time
    mu       sync.Mutex
}

func (rl *RateLimiter) Allow(clientIP string) bool {
    rl.mu.Lock()
    defer rl.mu.Unlock()
    
    now := time.Now()
    
    // 清理过期的请求记录
    if requests, exists := rl.requests[clientIP]; exists {
        validRequests := make([]time.Time, 0)
        for _, reqTime := range requests {
            if now.Sub(reqTime) <= rl.window {
                validRequests = append(validRequests, reqTime)
            }
        }
        rl.requests[clientIP] = validRequests
    }
    
    // 检查是否超过限制
    if len(rl.requests[clientIP]) >= rl.limit {
        return false
    }
    
    // 记录当前请求
    if rl.requests[clientIP] == nil {
        rl.requests[clientIP] = make([]time.Time, 0)
    }
    rl.requests[clientIP] = append(rl.requests[clientIP], now)
    
    return true
}

type CircuitBreaker struct {
    maxFailures int
    resetTimeout time.Duration
    failures    int
    lastFailure time.Time
    state       CircuitState
    mu          sync.Mutex
}

type CircuitState int

const (
    CircuitClosed CircuitState = iota
    CircuitOpen
    CircuitHalfOpen
)

func (cb *CircuitBreaker) Call(fn func() error) error {
    cb.mu.Lock()
    defer cb.mu.Unlock()
    
    switch cb.state {
    case CircuitOpen:
        if time.Since(cb.lastFailure) > cb.resetTimeout {
            cb.state = CircuitHalfOpen
        } else {
            return errors.New("circuit breaker is open")
        }
    case CircuitHalfOpen:
        // 允许一个请求通过
    }
    
    err := fn()
    if err != nil {
        cb.failures++
        cb.lastFailure = time.Now()
        
        if cb.failures >= cb.maxFailures {
            cb.state = CircuitOpen
        }
        
        return err
    }
    
    // 成功，重置状态
    cb.failures = 0
    cb.state = CircuitClosed
    return nil
}
```

## 核心组件

### 1. 负载均衡器接口
```go
// 负载均衡器接口定义
type LoadBalancer interface {
    NextServer() *Server
    AddServer(server Server)
    RemoveServer(serverID string)
    UpdateServer(server Server)
    GetServers() []Server
    GetStats() BalancerStats
}

type BalancerStats struct {
    TotalRequests   int64
    ActiveServers   int
    InactiveServers int
    AverageLatency  time.Duration
}

// 负载均衡器工厂
type BalancerFactory struct {
    healthChecker *HealthChecker
}

func (bf *BalancerFactory) CreateBalancer(algorithm string, servers []Server, config map[string]interface{}) (LoadBalancer, error) {
    switch algorithm {
    case "round_robin":
        return NewRoundRobinBalancer(servers), nil
    case "weighted_round_robin":
        return NewWeightedRoundRobinBalancer(servers), nil
    case "least_connections":
        return NewLeastConnectionsBalancer(servers), nil
    case "consistent_hash":
        replicas := config["replicas"].(int)
        balancer := NewConsistentHashBalancer(replicas)
        for _, server := range servers {
            balancer.AddServer(server)
        }
        return balancer, nil
    case "adaptive_weight":
        return NewAdaptiveWeightBalancer(servers), nil
    default:
        return nil, fmt.Errorf("unsupported algorithm: %s", algorithm)
    }
}
```

### 2. 反向代理实现
```go
// HTTP反向代理
type ReverseProxy struct {
    balancer    LoadBalancer
    transport   *http.Transport
    retryCount  int
    retryDelay  time.Duration
    metrics     *ProxyMetrics
}

type ProxyMetrics struct {
    RequestCount    int64
    ErrorCount      int64
    TotalLatency    time.Duration
    mu              sync.RWMutex
}

func NewReverseProxy(balancer LoadBalancer) *ReverseProxy {
    return &ReverseProxy{
        balancer: balancer,
        transport: &http.Transport{
            MaxIdleConns:        100,
            MaxIdleConnsPerHost: 10,
            IdleConnTimeout:     90 * time.Second,
        },
        retryCount: 3,
        retryDelay: 100 * time.Millisecond,
        metrics:    &ProxyMetrics{},
    }
}

func (rp *ReverseProxy) ServeHTTP(w http.ResponseWriter, r *http.Request) {
    start := time.Now()
    
    atomic.AddInt64(&rp.metrics.RequestCount, 1)
    
    var lastErr error
    for attempt := 0; attempt <= rp.retryCount; attempt++ {
        server := rp.balancer.NextServer()
        if server == nil {
            http.Error(w, "No available servers", http.StatusServiceUnavailable)
            atomic.AddInt64(&rp.metrics.ErrorCount, 1)
            return
        }
        
        err := rp.proxyRequest(w, r, server)
        if err == nil {
            // 记录成功的响应时间
            latency := time.Since(start)
            rp.recordLatency(latency)
            return
        }
        
        lastErr = err
        if attempt < rp.retryCount {
            time.Sleep(rp.retryDelay)
        }
    }
    
    // 所有重试都失败
    log.Printf("All retry attempts failed: %v", lastErr)
    http.Error(w, "Service temporarily unavailable", http.StatusBadGateway)
    atomic.AddInt64(&rp.metrics.ErrorCount, 1)
}

func (rp *ReverseProxy) proxyRequest(w http.ResponseWriter, r *http.Request, server *Server) error {
    // 构建目标URL
    targetURL := fmt.Sprintf("http://%s%s", server.Address, r.URL.Path)
    if r.URL.RawQuery != "" {
        targetURL += "?" + r.URL.RawQuery
    }
    
    // 创建新的请求
    proxyReq, err := http.NewRequest(r.Method, targetURL, r.Body)
    if err != nil {
        return err
    }
    
    // 复制请求头
    for key, values := range r.Header {
        for _, value := range values {
            proxyReq.Header.Add(key, value)
        }
    }
    
    // 添加代理相关的头
    proxyReq.Header.Set("X-Forwarded-For", r.RemoteAddr)
    proxyReq.Header.Set("X-Forwarded-Proto", "http")
    
    // 发送请求
    client := &http.Client{Transport: rp.transport}
    resp, err := client.Do(proxyReq)
    if err != nil {
        return err
    }
    defer resp.Body.Close()
    
    // 复制响应头
    for key, values := range resp.Header {
        for _, value := range values {
            w.Header().Add(key, value)
        }
    }
    
    // 设置状态码
    w.WriteHeader(resp.StatusCode)
    
    // 复制响应体
    _, err = io.Copy(w, resp.Body)
    return err
}

func (rp *ReverseProxy) recordLatency(latency time.Duration) {
    rp.metrics.mu.Lock()
    defer rp.metrics.mu.Unlock()
    rp.metrics.TotalLatency += latency
}

func (rp *ReverseProxy) GetMetrics() ProxyMetrics {
    rp.metrics.mu.RLock()
    defer rp.metrics.mu.RUnlock()
    return *rp.metrics
}
```

### 3. 服务发现集成
```go
// 服务发现接口
type ServiceDiscovery interface {
    Discover(serviceName string) ([]Server, error)
    Watch(serviceName string) (<-chan []Server, error)
    Register(serviceName string, server Server) error
    Deregister(serviceName string, serverID string) error
}

// 基于etcd的服务发现
type EtcdServiceDiscovery struct {
    client *clientv3.Client
    prefix string
}

func NewEtcdServiceDiscovery(client *clientv3.Client, prefix string) *EtcdServiceDiscovery {
    return &EtcdServiceDiscovery{
        client: client,
        prefix: prefix,
    }
}

func (esd *EtcdServiceDiscovery) Discover(serviceName string) ([]Server, error) {
    key := fmt.Sprintf("%s/%s/", esd.prefix, serviceName)
    resp, err := esd.client.Get(context.Background(), key, clientv3.WithPrefix())
    if err != nil {
        return nil, err
    }
    
    var servers []Server
    for _, kv := range resp.Kvs {
        var server Server
        if err := json.Unmarshal(kv.Value, &server); err == nil {
            servers = append(servers, server)
        }
    }
    
    return servers, nil
}

func (esd *EtcdServiceDiscovery) Watch(serviceName string) (<-chan []Server, error) {
    key := fmt.Sprintf("%s/%s/", esd.prefix, serviceName)
    watchCh := esd.client.Watch(context.Background(), key, clientv3.WithPrefix())
    
    serversCh := make(chan []Server, 1)
    
    go func() {
        defer close(serversCh)
        
        // 发送初始服务列表
        if servers, err := esd.Discover(serviceName); err == nil {
            serversCh <- servers
        }
        
        // 监听变化
        for watchResp := range watchCh {
            if servers, err := esd.Discover(serviceName); err == nil {
                serversCh <- servers
            }
        }
    }()
    
    return serversCh, nil
}

// 动态负载均衡器
type DynamicLoadBalancer struct {
    serviceName     string
    serviceDiscovery ServiceDiscovery
    balancer        LoadBalancer
    balancerFactory *BalancerFactory
    algorithm       string
    config          map[string]interface{}
    mu              sync.RWMutex
}

func NewDynamicLoadBalancer(serviceName string, sd ServiceDiscovery, algorithm string, config map[string]interface{}) *DynamicLoadBalancer {
    dlb := &DynamicLoadBalancer{
        serviceName:     serviceName,
        serviceDiscovery: sd,
        balancerFactory: &BalancerFactory{},
        algorithm:       algorithm,
        config:          config,
    }
    
    dlb.startWatching()
    return dlb
}

func (dlb *DynamicLoadBalancer) startWatching() {
    serversCh, err := dlb.serviceDiscovery.Watch(dlb.serviceName)
    if err != nil {
        log.Printf("Failed to watch service %s: %v", dlb.serviceName, err)
        return
    }
    
    go func() {
        for servers := range serversCh {
            dlb.updateServers(servers)
        }
    }()
}

func (dlb *DynamicLoadBalancer) updateServers(servers []Server) {
    dlb.mu.Lock()
    defer dlb.mu.Unlock()
    
    // 创建新的负载均衡器
    newBalancer, err := dlb.balancerFactory.CreateBalancer(dlb.algorithm, servers, dlb.config)
    if err != nil {
        log.Printf("Failed to create balancer: %v", err)
        return
    }
    
    dlb.balancer = newBalancer
    log.Printf("Updated servers for service %s: %d servers", dlb.serviceName, len(servers))
}

func (dlb *DynamicLoadBalancer) NextServer() *Server {
    dlb.mu.RLock()
    defer dlb.mu.RUnlock()
    
    if dlb.balancer == nil {
        return nil
    }
    
    return dlb.balancer.NextServer()
}
```

## 使用场景

### 1. API网关负载均衡
```go
// API网关实现
type APIGateway struct {
    routes map[string]*DynamicLoadBalancer
    mu     sync.RWMutex
}

func NewAPIGateway() *APIGateway {
    return &APIGateway{
        routes: make(map[string]*DynamicLoadBalancer),
    }
}

func (ag *APIGateway) AddRoute(path, serviceName string, balancer *DynamicLoadBalancer) {
    ag.mu.Lock()
    defer ag.mu.Unlock()
    ag.routes[path] = balancer
}

func (ag *APIGateway) ServeHTTP(w http.ResponseWriter, r *http.Request) {
    // 路由匹配
    balancer := ag.findBalancer(r.URL.Path)
    if balancer == nil {
        http.Error(w, "Service not found", http.StatusNotFound)
        return
    }
    
    // 获取目标服务器
    server := balancer.NextServer()
    if server == nil {
        http.Error(w, "No available servers", http.StatusServiceUnavailable)
        return
    }
    
    // 代理请求
    proxy := NewReverseProxy(balancer)
    proxy.ServeHTTP(w, r)
}

func (ag *APIGateway) findBalancer(path string) *DynamicLoadBalancer {
    ag.mu.RLock()
    defer ag.mu.RUnlock()
    
    // 精确匹配
    if balancer, exists := ag.routes[path]; exists {
        return balancer
    }
    
    // 前缀匹配
    for routePath, balancer := range ag.routes {
        if strings.HasPrefix(path, routePath) {
            return balancer
        }
    }
    
    return nil
}
```

### 2. 数据库连接池负载均衡
```go
// 数据库连接池负载均衡
type DBLoadBalancer struct {
    pools    map[string]*sql.DB
    balancer LoadBalancer
    mu       sync.RWMutex
}

func NewDBLoadBalancer(servers []Server) (*DBLoadBalancer, error) {
    pools := make(map[string]*sql.DB)
    
    for _, server := range servers {
        dsn := fmt.Sprintf("user:password@tcp(%s)/database", server.Address)
        db, err := sql.Open("mysql", dsn)
        if err != nil {
            return nil, err
        }
        
        // 配置连接池
        db.SetMaxOpenConns(25)
        db.SetMaxIdleConns(5)
        db.SetConnMaxLifetime(5 * time.Minute)
        
        pools[server.ID] = db
    }
    
    return &DBLoadBalancer{
        pools:    pools,
        balancer: NewWeightedRoundRobinBalancer(servers),
    }, nil
}

func (dblb *DBLoadBalancer) Query(query string, args ...interface{}) (*sql.Rows, error) {
    server := dblb.balancer.NextServer()
    if server == nil {
        return nil, errors.New("no available database servers")
    }
    
    dblb.mu.RLock()
    db := dblb.pools[server.ID]
    dblb.mu.RUnlock()
    
    return db.Query(query, args...)
}

func (dblb *DBLoadBalancer) Exec(query string, args ...interface{}) (sql.Result, error) {
    server := dblb.balancer.NextServer()
    if server == nil {
        return nil, errors.New("no available database servers")
    }
    
    dblb.mu.RLock()
    db := dblb.pools[server.ID]
    dblb.mu.RUnlock()
    
    return db.Exec(query, args...)
}
```

### 3. gRPC负载均衡
```go
// gRPC客户端负载均衡
type GRPCLoadBalancer struct {
    connections map[string]*grpc.ClientConn
    balancer    LoadBalancer
    mu          sync.RWMutex
}

func NewGRPCLoadBalancer(servers []Server) (*GRPCLoadBalancer, error) {
    connections := make(map[string]*grpc.ClientConn)
    
    for _, server := range servers {
        conn, err := grpc.Dial(server.Address, grpc.WithInsecure())
        if err != nil {
            return nil, err
        }
        connections[server.ID] = conn
    }
    
    return &GRPCLoadBalancer{
        connections: connections,
        balancer:    NewRoundRobinBalancer(servers),
    }, nil
}

func (glb *GRPCLoadBalancer) GetConnection() (*grpc.ClientConn, error) {
    server := glb.balancer.NextServer()
    if server == nil {
        return nil, errors.New("no available gRPC servers")
    }
    
    glb.mu.RLock()
    conn := glb.connections[server.ID]
    glb.mu.RUnlock()
    
    return conn, nil
}

func (glb *GRPCLoadBalancer) Close() error {
    glb.mu.Lock()
    defer glb.mu.Unlock()
    
    for _, conn := range glb.connections {
        conn.Close()
    }
    
    return nil
}
```

## 技术分析

### 优势
1. **高可用性**：通过多服务器部署避免单点故障
2. **可扩展性**：支持水平扩展，动态添加/移除服务器
3. **性能优化**：合理分发请求，提高资源利用率
4. **故障隔离**：自动检测和隔离故障服务器
5. **灵活配置**：支持多种负载均衡算法和策略

### 挑战与限制
1. **复杂性增加**：引入额外的组件和配置复杂度
2. **单点故障**：负载均衡器本身可能成为单点故障
3. **状态管理**：会话保持等状态管理增加复杂性
4. **延迟开销**：额外的网络跳转增加延迟
5. **配置管理**：需要维护服务器列表和配置信息

### 最佳实践

#### 1. 监控和告警
```go
// 负载均衡器监控
type LoadBalancerMonitor struct {
    balancer LoadBalancer
    metrics  *BalancerMetrics
}

type BalancerMetrics struct {
    RequestsPerSecond float64
    ErrorRate         float64
    AverageLatency    time.Duration
    ServerHealth      map[string]bool
}

func (lbm *LoadBalancerMonitor) StartMonitoring() {
    ticker := time.NewTicker(30 * time.Second)
    defer ticker.Stop()
    
    for {
        select {
        case <-ticker.C:
            lbm.collectMetrics()
            lbm.checkAlerts()
        }
    }
}

func (lbm *LoadBalancerMonitor) checkAlerts() {
    if lbm.metrics.ErrorRate > 0.05 { // 5%错误率
        log.Printf("ALERT: High error rate: %.2f%%", lbm.metrics.ErrorRate*100)
    }
    
    if lbm.metrics.AverageLatency > 1*time.Second {
        log.Printf("ALERT: High latency: %v", lbm.metrics.AverageLatency)
    }
    
    activeServers := 0
    for _, healthy := range lbm.metrics.ServerHealth {
        if healthy {
            activeServers++
        }
    }
    
    if activeServers == 0 {
        log.Printf("CRITICAL: No active servers available")
    } else if activeServers == 1 {
        log.Printf("WARNING: Only one active server remaining")
    }
}
```

#### 2. 优雅关闭
```go
// 优雅关闭实现
type GracefulLoadBalancer struct {
    balancer    LoadBalancer
    proxy       *ReverseProxy
    server      *http.Server
    shutdown    chan struct{}
    activeConns int64
}

func (glb *GracefulLoadBalancer) Shutdown(ctx context.Context) error {
    log.Println("Starting graceful shutdown...")
    
    // 停止接受新连接
    close(glb.shutdown)
    
    // 等待现有连接完成
    ticker := time.NewTicker(1 * time.Second)
    defer ticker.Stop()
    
    for {
        select {
        case <-ctx.Done():
            log.Println("Shutdown timeout, forcing close")
            return ctx.Err()
        case <-ticker.C:
            if atomic.LoadInt64(&glb.activeConns) == 0 {
                log.Println("All connections closed, shutdown complete")
                return nil
            }
            log.Printf("Waiting for %d connections to close", atomic.LoadInt64(&glb.activeConns))
        }
    }
}
```

## 架构师级深度分析

### 1. 企业级负载均衡架构设计决策框架

#### 1.1 架构分层设计
```go
// 企业级负载均衡架构
type EnterpriseLoadBalancer struct {
    // 接入层：全局负载均衡
    GlobalLB    *GlobalLoadBalancer
    // 区域层：区域负载均衡
    RegionalLB  map[string]*RegionalLoadBalancer
    // 集群层：集群内负载均衡
    ClusterLB   map[string]*ClusterLoadBalancer
    // 服务层：服务实例负载均衡
    ServiceLB   map[string]*ServiceLoadBalancer
    
    // 配置中心
    ConfigCenter *ConfigCenter
    // 服务发现
    ServiceDiscovery *ServiceDiscovery
    // 监控系统
    MonitoringSystem *MonitoringSystem
}

// 全局负载均衡器（DNS级别）
type GlobalLoadBalancer struct {
    DNSProvider    DNSProvider
    HealthChecker  *GlobalHealthChecker
    TrafficPolicy  *TrafficPolicy
    GeoRouting     *GeoRoutingEngine
}

// 区域负载均衡器
type RegionalLoadBalancer struct {
    Region         string
    Clusters       []*ClusterInfo
    FailoverPolicy *FailoverPolicy
    LoadShedding   *LoadSheddingPolicy
}
```

#### 1.2 技术选型决策矩阵
| 场景 | 推荐方案 | 性能指标 | 适用规模 | 复杂度 |
|------|----------|----------|----------|--------|
| 高并发Web服务 | Nginx + Consul | 100K+ QPS | 大型 | 中等 |
| 微服务网关 | Envoy + Istio | 50K+ QPS | 中大型 | 高 |
| 数据库代理 | HAProxy + Keepalived | 10K+ TPS | 中型 | 低 |
| 缓存集群 | 一致性哈希 + Redis Cluster | 1M+ OPS | 大型 | 中等 |
| 消息队列 | 轮询 + Kafka Partition | 100K+ MPS | 大型 | 低 |

### 2. 金融级高可用负载均衡实战案例

#### 2.1 交易系统负载均衡架构
```go
// 金融交易系统负载均衡
type TradingSystemLB struct {
    // 主备双活架构
    PrimaryDC   *DataCenterLB
    SecondaryDC *DataCenterLB
    
    // 交易路由引擎
    TradingRouter *TradingRouter
    // 风控引擎
    RiskEngine    *RiskEngine
    // 审计日志
    AuditLogger   *AuditLogger
}

type TradingRouter struct {
    // 按交易类型路由
    RouteByTradeType map[TradeType]*ServiceCluster
    // 按用户等级路由
    RouteByUserLevel map[UserLevel]*ServiceCluster
    // 按地域路由
    RouteByRegion    map[Region]*ServiceCluster
}

// 实现交易请求路由
func (tr *TradingRouter) RouteTradeRequest(req *TradeRequest) (*ServiceInstance, error) {
    // 1. 风控检查
    if !tr.RiskEngine.CheckRisk(req) {
        return nil, errors.New("risk check failed")
    }
    
    // 2. 根据交易类型选择集群
    cluster := tr.RouteByTradeType[req.TradeType]
    if cluster == nil {
        return nil, errors.New("no cluster for trade type")
    }
    
    // 3. 根据用户等级选择实例
    userLevel := tr.getUserLevel(req.UserID)
    instances := cluster.GetInstancesByLevel(userLevel)
    
    // 4. 负载均衡选择实例
    return tr.selectInstance(instances, req)
}
```

#### 2.2 性能测试数据
```bash
# 压测配置
并发用户: 10,000
测试时长: 30分钟
交易类型: 股票买卖

# 性能指标
QPS: 50,000+
平均响应时间: 15ms
P99响应时间: 50ms
错误率: 0.001%
可用性: 99.99%

# 资源使用
CPU使用率: 60%
内存使用率: 70%
网络带宽: 1Gbps
```

### 3. 大规模电商系统负载均衡架构演进

#### 3.1 架构演进路径
```go
// 第一阶段：单体应用 + 简单负载均衡
type Phase1Architecture struct {
    LoadBalancer *SimpleRoundRobinLB
    AppServers   []*AppServer
    Database     *Database
}

// 第二阶段：微服务 + 服务网格
type Phase2Architecture struct {
    APIGateway    *APIGateway
    ServiceMesh   *ServiceMesh
    Microservices map[string]*MicroserviceCluster
    Databases     map[string]*DatabaseCluster
}

// 第三阶段：云原生 + 智能负载均衡
type Phase3Architecture struct {
    CloudLB       *CloudLoadBalancer
    K8sIngress    *KubernetesIngress
    ServiceMesh   *IstioServiceMesh
    AIOptimizer   *AILoadBalancingOptimizer
}
```

#### 3.2 双11大促负载均衡策略
```go
// 大促期间动态负载均衡
type PromotionLoadBalancer struct {
    NormalPolicy    LoadBalancingPolicy
    PromotionPolicy LoadBalancingPolicy
    TrafficPredictor *TrafficPredictor
    AutoScaler      *AutoScaler
}

func (plb *PromotionLoadBalancer) HandlePromotionTraffic() {
    // 1. 流量预测
    prediction := plb.TrafficPredictor.PredictTraffic()
    
    // 2. 预热策略
    if prediction.PeakTime.Sub(time.Now()) < 30*time.Minute {
        plb.preWarmInstances(prediction.ExpectedQPS)
    }
    
    // 3. 动态扩容
    if prediction.ExpectedQPS > plb.getCurrentCapacity() {
        plb.AutoScaler.ScaleOut(prediction.ExpectedQPS)
    }
    
    // 4. 切换负载均衡策略
    plb.switchToPromotionPolicy()
}

// 流量削峰策略
func (plb *PromotionLoadBalancer) implementTrafficShaping() {
    // 令牌桶限流
    tokenBucket := NewTokenBucket(10000, 1000) // 10K QPS, 1K burst
    
    // 队列缓冲
    requestQueue := make(chan *Request, 50000)
    
    // 优先级队列
    priorityQueue := NewPriorityQueue()
}
```

### 4. 微服务架构中的负载均衡最佳实践

#### 4.1 服务网格集成
```go
// Istio集成的负载均衡
type IstioLoadBalancer struct {
    VirtualService   *VirtualService
    DestinationRule  *DestinationRule
    ServiceEntry     *ServiceEntry
    EnvoyFilter      *EnvoyFilter
}

// 流量分割配置
func (ilb *IstioLoadBalancer) ConfigureTrafficSplit() {
    virtualService := &VirtualService{
        Spec: VirtualServiceSpec{
            HTTP: []HTTPRoute{{
                Match: []HTTPMatchRequest{{
                    Headers: map[string]StringMatch{
                        "canary": {Exact: "true"},
                    },
                }},
                Route: []HTTPRouteDestination{{
                    Destination: Destination{
                        Host:   "my-service",
                        Subset: "canary",
                    },
                    Weight: 10, // 10%流量到金丝雀版本
                }},
            }},
        },
    }
}
```

#### 4.2 多集群负载均衡
```go
// 跨集群负载均衡
type MultiClusterLoadBalancer struct {
    Clusters        map[string]*ClusterInfo
    CrossClusterLB  *CrossClusterLB
    FailoverPolicy  *FailoverPolicy
    LatencyOptimizer *LatencyOptimizer
}

type ClusterInfo struct {
    ClusterID    string
    Region       string
    Zone         string
    Capacity     int
    CurrentLoad  float64
    Latency      time.Duration
    HealthScore  float64
}

// 智能集群选择
func (mclb *MultiClusterLoadBalancer) SelectCluster(req *Request) *ClusterInfo {
    // 1. 地域优先
    localClusters := mclb.getLocalClusters(req.ClientRegion)
    
    // 2. 健康度过滤
    healthyClusters := mclb.filterHealthyClusters(localClusters)
    
    // 3. 负载均衡
    return mclb.selectByLoad(healthyClusters)
}
```

### 5. 踩坑经验与解决方案

#### 5.1 常见问题及解决方案

**问题1：雪崩效应**
```go
// 问题：单个服务故障导致整体系统崩溃
// 解决方案：熔断器 + 限流 + 降级
type CircuitBreakerLB struct {
    circuitBreaker *CircuitBreaker
    rateLimiter    *RateLimiter
    fallbackHandler *FallbackHandler
}

func (cblb *CircuitBreakerLB) HandleRequest(req *Request) (*Response, error) {
    // 1. 限流检查
    if !cblb.rateLimiter.Allow() {
        return cblb.fallbackHandler.Handle(req)
    }
    
    // 2. 熔断检查
    return cblb.circuitBreaker.Execute(func() (*Response, error) {
        return cblb.forwardRequest(req)
    })
}
```

**问题2：热点数据倾斜**
```go
// 问题：一致性哈希导致热点数据集中在少数节点
// 解决方案：虚拟节点 + 热点检测 + 动态迁移
type HotspotAwareConsistentHash struct {
    ring         *ConsistentHashRing
    hotspotDetector *HotspotDetector
    migrator     *DataMigrator
}

func (hach *HotspotAwareConsistentHash) Get(key string) *Node {
    node := hach.ring.Get(key)
    
    // 热点检测
    if hach.hotspotDetector.IsHotspot(key, node) {
        // 动态迁移到负载较低的节点
        return hach.migrator.MigrateToLightNode(key)
    }
    
    return node
}
```

**问题3：会话粘性导致负载不均**
```go
// 问题：会话粘性导致某些服务器负载过高
// 解决方案：会话复制 + 动态权重调整
type SessionAwareLB struct {
    sessionStore   *DistributedSessionStore
    weightAdjuster *DynamicWeightAdjuster
}

func (salb *SessionAwareLB) RouteRequest(req *Request) *Server {
    // 1. 检查会话是否可以迁移
    if salb.sessionStore.IsSessionMigratable(req.SessionID) {
        // 选择负载最低的服务器
        return salb.selectLeastLoadedServer()
    }
    
    // 2. 路由到原服务器，但调整权重
    server := salb.getSessionServer(req.SessionID)
    salb.weightAdjuster.AdjustWeight(server)
    return server
}
```

### 6. 性能优化实战

#### 6.1 零拷贝优化
```go
// 使用零拷贝技术优化数据传输
type ZeroCopyProxy struct {
    upstream   net.Conn
    downstream net.Conn
}

func (zcp *ZeroCopyProxy) ProxyData() error {
    // 使用splice系统调用实现零拷贝
    if runtime.GOOS == "linux" {
        return zcp.spliceProxy()
    }
    
    // 回退到普通拷贝
    return zcp.normalProxy()
}

func (zcp *ZeroCopyProxy) spliceProxy() error {
    // 创建管道
    r, w, err := os.Pipe()
    if err != nil {
        return err
    }
    defer r.Close()
    defer w.Close()
    
    // 使用splice进行零拷贝传输
    // 这里需要使用syscall包调用splice系统调用
    return nil
}
```

#### 6.2 内存池优化
```go
// 对象池减少GC压力
type BufferPool struct {
    pool sync.Pool
}

func NewBufferPool() *BufferPool {
    return &BufferPool{
        pool: sync.Pool{
            New: func() interface{} {
                return make([]byte, 64*1024) // 64KB缓冲区
            },
        },
    }
}

func (bp *BufferPool) Get() []byte {
    return bp.pool.Get().([]byte)
}

func (bp *BufferPool) Put(buf []byte) {
    if cap(buf) == 64*1024 {
        bp.pool.Put(buf[:0]) // 重置长度但保留容量
    }
}
```

#### 6.3 性能基准测试
```go
// 负载均衡器性能测试
func BenchmarkLoadBalancer(b *testing.B) {
    servers := createTestServers(10)
    lb := NewRoundRobinBalancer(servers)
    
    b.ResetTimer()
    b.RunParallel(func(pb *testing.PB) {
        for pb.Next() {
            server := lb.NextServer()
            if server == nil {
                b.Fatal("No server returned")
            }
        }
    })
}

// 性能测试结果
// BenchmarkLoadBalancer-8    50000000    25.3 ns/op    0 B/op    0 allocs/op
```

### 7. 监控与运维实践

#### 7.1 全链路监控
```go
// 负载均衡器监控指标
type LoadBalancerMetrics struct {
    // 基础指标
    RequestCount     prometheus.Counter
    ErrorCount       prometheus.Counter
    ResponseTime     prometheus.Histogram
    ActiveConnections prometheus.Gauge
    
    // 业务指标
    ThroughputQPS    prometheus.Gauge
    SuccessRate      prometheus.Gauge
    ServerHealth     prometheus.GaugeVec
    
    // 资源指标
    CPUUsage         prometheus.Gauge
    MemoryUsage      prometheus.Gauge
    NetworkIO        prometheus.CounterVec
}

// 监控数据收集
func (lbm *LoadBalancerMetrics) RecordRequest(duration time.Duration, success bool) {
    lbm.RequestCount.Inc()
    lbm.ResponseTime.Observe(duration.Seconds())
    
    if !success {
        lbm.ErrorCount.Inc()
    }
}
```

#### 7.2 自动化运维
```go
// 自动故障恢复
type AutoRecoverySystem struct {
    healthChecker   *HealthChecker
    alertManager    *AlertManager
    recoveryActions map[string]RecoveryAction
}

type RecoveryAction interface {
    Execute(incident *Incident) error
    Rollback() error
}

// 服务器重启恢复动作
type ServerRestartAction struct {
    serverManager *ServerManager
}

func (sra *ServerRestartAction) Execute(incident *Incident) error {
    server := incident.AffectedServer
    
    // 1. 从负载均衡器移除
    sra.serverManager.RemoveFromLB(server)
    
    // 2. 重启服务器
    err := sra.serverManager.RestartServer(server)
    if err != nil {
        return err
    }
    
    // 3. 健康检查通过后重新加入
    if sra.serverManager.HealthCheck(server) {
        sra.serverManager.AddToLB(server)
    }
    
    return nil
}
```

### 8. 面试要点总结

#### 8.1 系统设计题
**题目：设计一个支持千万级QPS的负载均衡系统**

**回答框架：**
1. **需求分析**
   - QPS: 10M+
   - 可用性: 99.99%
   - 延迟: P99 < 10ms
   - 扩展性: 支持动态扩缩容

2. **架构设计**
   - 分层架构：DNS -> CDN -> LB -> 应用
   - 水平扩展：多个LB实例
   - 异地多活：多数据中心部署

3. **技术选型**
   - 硬件LB: F5/A10 (入口)
   - 软件LB: Nginx/HAProxy (应用层)
   - 服务发现: Consul/etcd
   - 监控: Prometheus + Grafana

4. **性能优化**
   - 零拷贝技术
   - 连接池复用
   - 内存池管理
   - CPU亲和性绑定

#### 8.2 高频技术问题

**Q1: 如何解决负载均衡的单点故障？**
```go
// 主备模式 + VIP漂移
type HALoadBalancer struct {
    Primary   *LoadBalancer
    Secondary *LoadBalancer
    VIP       string
    Keepalived *Keepalived
}

// 集群模式 + 一致性哈希
type ClusterLoadBalancer struct {
    Nodes []LoadBalancerNode
    Ring  *ConsistentHashRing
}
```

**Q2: 如何实现跨数据中心的负载均衡？**
```go
// 全局负载均衡
type GlobalLoadBalancer struct {
    DataCenters map[string]*DataCenter
    DNSProvider DNSProvider
    GeoIP       *GeoIPService
    LatencyMap  map[string]map[string]time.Duration
}

func (glb *GlobalLoadBalancer) RouteRequest(clientIP string) *DataCenter {
    // 1. 地理位置路由
    region := glb.GeoIP.GetRegion(clientIP)
    
    // 2. 延迟优化路由
    return glb.selectByLatency(region)
}
```

**Q3: 如何处理负载均衡中的会话保持？**
```go
// 多种会话保持策略
type SessionAffinityStrategy interface {
    GetServer(sessionID string) *Server
    UpdateSession(sessionID string, server *Server)
}

// IP哈希策略
type IPHashStrategy struct {
    servers []Server
}

// Cookie策略
type CookieStrategy struct {
    sessionStore map[string]*Server
}

// 一致性哈希策略
type ConsistentHashStrategy struct {
    ring *ConsistentHashRing
}
```

## 面试常见问题

### 1. 常见的负载均衡算法有哪些？各自的适用场景是什么？
**回答要点**：
- **轮询（Round Robin）**：简单公平，适用于服务器性能相近的场景
- **加权轮询（Weighted Round Robin）**：考虑服务器性能差异，适用于异构环境
- **最少连接（Least Connections）**：适用于长连接场景，如数据库连接
- **一致性哈希（Consistent Hashing）**：适用于缓存场景，减少数据迁移
- **IP哈希**：实现会话保持，适用于有状态应用

### 2. 如何处理服务器故障？健康检查机制如何设计？
**回答要点**：
- **主动健康检查**：定期发送HTTP/TCP请求检查服务器状态
- **被动健康检查**：根据实际请求的成功/失败情况判断
- **故障转移**：自动将流量切换到健康的服务器
- **恢复检测**：故障服务器恢复后自动重新加入服务
- **熔断机制**：防止故障服务器影响整体性能

### 3. L4和L7负载均衡的区别是什么？
**回答要点**：
- **L4负载均衡**：
  - 工作在传输层，基于IP和端口
  - 性能高，延迟低
  - 功能相对简单，无法基于内容路由
  - 适用于高性能场景
- **L7负载均衡**：
  - 工作在应用层，可以解析HTTP内容
  - 支持基于URL、Header等内容路由
  - 功能丰富，但性能相对较低
  - 适用于复杂路由需求

### 4. 如何实现会话保持（Session Affinity）？
**回答要点**：
- **IP哈希**：基于客户端IP进行哈希，简单但可能不均匀
- **Cookie**：在响应中设置Cookie，后续请求根据Cookie路由
- **URL重写**：在URL中添加服务器标识
- **应用层会话共享**：使用Redis等外部存储共享会话

### 5. 在Go语言中如何实现高性能的负载均衡器？
**回答要点**：
```go
// 性能优化要点

// 1. 使用读写锁减少锁竞争
type HighPerformanceBalancer struct {
    servers []Server
    current int64
    mu      sync.RWMutex // 读写锁
}

// 2. 原子操作避免锁
func (hpb *HighPerformanceBalancer) NextServer() *Server {
    index := atomic.AddInt64(&hpb.current, 1) % int64(len(hpb.servers))
    return &hpb.servers[index]
}

// 3. 连接池复用
var httpClient = &http.Client{
    Transport: &http.Transport{
        MaxIdleConns:        100,
        MaxIdleConnsPerHost: 10,
        IdleConnTimeout:     90 * time.Second,
    },
}

// 4. 异步健康检查
func (hpb *HighPerformanceBalancer) asyncHealthCheck() {
    go func() {
        for _, server := range hpb.servers {
            go hpb.checkServerHealth(server)
        }
    }()
}

// 5. 内存池减少GC压力
var bufferPool = sync.Pool{
    New: func() interface{} {
        return make([]byte, 4096)
    },
}
```

### 6. 如何设计一个支持动态配置的负载均衡器？
**回答要点**：
- **配置热更新**：支持不重启服务更新配置
- **服务发现集成**：自动发现和注册服务实例
- **版本管理**：支持配置版本控制和回滚
- **A/B测试**：支持流量分割和灰度发布
- **监控集成**：实时监控配置变更效果